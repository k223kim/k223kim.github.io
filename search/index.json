[{"content":"Disclaimer These examples are based on the nestjs document Basic Setting 1 nest new controller_practice This will set up a new nest project with corresponding boilerplate code I have selected npm for the package manager running npm run start:dev will start the server on the localhost when accessing http://localhost:3000, you\u0026rsquo;ll see 1 Hello World! Controllers receive specific requests for the application routing controls which controller receives which request each controller has more than one route different routes can perform different actions nest g resource [name] create a CRUD resource generates NestJS building blocks (modules, service, controller classes), entity class, DTO classes, testing (.spec) files For our example, run nest g resource cats @Controller() Required to define a basic controller can assign an optional route path prefix 1 2 //src/cats/cats.controller.ts @Controller(\u0026#39;cats\u0026#39;) notice that when doing nest g resource cats, it creates src/cats/cats.controller.ts that has a prefix cats curl http://localhost:3000/cats will call the GET method and call findAll() which will output This action returns all cats @Get() HTTP request method decorator this defines an endpoint to fetch resources Nest creates a handler for a specific endpoint for HTTP requests endpoint HTTP request method \u0026amp; route path route path prefix declared by the controller + path specified in the method\u0026rsquo;s decorator 1 2 3 4 5 6 7 8 9 10 //src/cats/cats.controller.ts @Controller(\u0026#39;cats\u0026#39;) export class CatsController { @Get(\u0026#39;breed\u0026#39;) //HTTP request method (GET) is made to this endpoint //route path: http://localhost:3000/cats/breed findAll(): string{ return \u0026#39;This action returns all cats\u0026#39;; } } // Nest will map \u0026#39;GET /cats/breed\u0026#39; to this handler Nest routes the request (GET) to findAll() the function name (findAll()) does not matter! @Req Request object (HTTP request) Access to the request object 1 2 3 4 5 6 7 8 //src/cats/cats.controller.ts import { Req } from \u0026#39;@nestjs/common\u0026#39; import { Request } from \u0026#39;express\u0026#39;; @Get() findAll(@Req() request: Request): string{ return \u0026#39;This action returns all cats\u0026#39;; } @Post() endpoint that creates new records it is called a \u0026lsquo;Post handler\u0026rsquo; Route wildcards 1 2 3 4 5 6 //src/cats/cats.controller.ts @Get(\u0026#39;ab*cd\u0026#39;) //matches abcd, ab_cd, abecd, etc findAll(){ return \u0026#39;This route uses a wildcard\u0026#39;; } @HttpCode(204) Response status code is 200 by default POST requests are 201 Can change the behavior 1 2 3 4 5 6 7 //src/cats/cats.controller.ts import { HttpCode } from \u0026#39;@nestjs/common\u0026#39;; @Post() @HttpCode(204) create(){ return \u0026#39;This action adds a new cat\u0026#39;; } @Header() specify custom response header 1 2 3 4 5 6 7 8 9 //src/cats/cats.controller.ts import { Header } from \u0026#39;@nestjs/common\u0026#39;; @Post() @Header(\u0026#39;Cache-Control\u0026#39;, \u0026#39;none\u0026#39;) create(){ return \u0026#39;This action adds a new cat\u0026#39; } // this addes \u0026#39;Cache-Control: none\u0026#39; to the Header this can be confirmed by the following 1 curl -X POST http://localhost:3000/cats -v this shows the newly added response header 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 * Trying 127.0.0.1:3000... * Connected to localhost (127.0.0.1) port 3000 (#0) \u0026gt; POST /cats HTTP/1.1 \u0026gt; Host: localhost:3000 \u0026gt; User-Agent: curl/7.86.0 \u0026gt; Accept: */* \u0026gt; * Mark bundle as not supporting multiuse \u0026lt; HTTP/1.1 201 Created \u0026lt; X-Powered-By: Express \u0026lt; Cache-Control: none \u0026lt; Content-Type: text/html; charset=utf-8 \u0026lt; Content-Length: 26 \u0026lt; ETag: W/\u0026#34;1a-2akZlhd5h5eyBoEmpkMg7vz8ALY\u0026#34; \u0026lt; Date: Mon, 19 Feb 2024 08:38:27 GMT \u0026lt; Connection: keep-alive \u0026lt; Keep-Alive: timeout=5 \u0026lt; * Connection #0 to host localhost left intact This action adds a new cat% @Redirect(url, status code) redirect can be overwritten by the returned url 1 2 3 4 5 6 7 8 9 10 11 12 //src/cats/cats.controller.ts @Get(\u0026#39;docs\u0026#39;) @Redirect(\u0026#39;https://docs.nestjs.com\u0026#39;, 302) //accessing localhost:3000/cats/docs/ will redirect to //https://docs.nestjs.com getDocs(@Query(\u0026#39;version\u0026#39;) version){ if (version \u0026amp;\u0026amp; version === \u0026#39;5\u0026#39;){ return {url: \u0026#39;https://docs.nestjs.com/v5/\u0026#39;}; //accessing localhost:3000/cats/docs?version=5 will redirec to //https://docs.nest.js.com/v5/ } } notice that the returned values will override any arguments passed to @Redirect() Route parameters (`@Get(\u0026rsquo;:var\u0026rsquo;), @Param(\u0026lsquo;var\u0026rsquo;) can capture dynamic value in the request URL route parameters declared in @Get() can be accessed with @Param() 1 2 3 4 5 6 7 8 9 10 11 //src/cats/cats.controller.ts @Get(\u0026#39;:id\u0026#39;)//dynamic token \u0026#39;id\u0026#39; declared findOne(@Param() params: any): string{ console.log(params.id); return `This action returns a #${params.id} cat`; } //OR findOne(@Param(\u0026#39;id\u0026#39;) params: string): string{ console.log(params); return `The action returns a #${params} cat`; } example with multiple route parameters 1 2 3 4 5 6 7 //src/cats/cats.controller.ts @Get(\u0026#39;:id/:number\u0026#39;) findOne(@Param() params: any): string{ console.log(params.id, params.number); return `This action returns ${params.id} and ${params.number}`; } // we can access this by http://localhost:3000/cats/2/100 but a better practice is to declare each param independently with its corresponding type 1 2 3 4 5 6 7 8 9 10 11 //src/cats/cats.controller.ts @Get(\u0026#39;:id/:number\u0026#39;) findOne( @Param(\u0026#39;id\u0026#39;) id: string, @Param(\u0026#39;number\u0026#39;) number: string, ){ return `id: ${id}, number: ${number}`; } // curl http://localhost:3000/cats/1/100 // results in // id: 1, number: 100 Sub-Domain Routing (@Controller({host:}, @HostParam) let us create another controller by using nest g co CatID 1 2 3 4 5 6 7 8 9 10 11 //default controller //src/app.controller.ts @Controller() export class AppController{ constructor(private readonly appService: AppService){} @Get() getHello(): string{ return \u0026#39;Hello World!\u0026#39; } } 1 2 3 4 5 6 7 8 9 10 // src/cat-id/cat-id.controller.ts (created by nest g co id) import { Controller, HostParam, Get } from \u0026#39;@nestjs/common\u0026#39;; @Controller({host: \u0026#39;:id.api.localhost\u0026#39;}) export class CatIdController { @Get() index(@HostParam(\u0026#39;id\u0026#39;) id: string): string{ return `this is sub routing to ${id}`; } } Notice how CatIdController has a endpoint that is the root route (localhost:3000). Also, notice how AppController also has a endpoint that is a root route (localhost:3000) 1 2 3 4 5 6 //src/app.module.ts @Module({ ... controllers: [AppController, CatIdController] ... }) since the app.module.ts has AppController first, that means that when having the same endpoint, the following will result in the same output (Hello World!) 1 2 curl http://localhost:3000 # Hello World! curl http://kaeun.api.localhost:3000 # Hello World! if we modify the app.module.ts as so, when having the same endpoint, CatIdController will be processed first 1 2 3 4 5 6 //src/app.module.ts @Module({ ... controllers: [CatIdController, AppController] ... }) This means the following 1 2 curl http://kaeun.api.localhost:3000 # this is sub routing to kaeun curl http://localhost:3000 # Hello World! Note When requesting to a host that is not in the host parameter, (e.g. http://kaeun.localhost:3000, this request is being requested to the original domain (i.e. http://localhost:3000) DTO (Data Transfer Object) object that defines how the data will be sent over the network recommended to define DTO schema using Typescript classes 1 2 3 4 5 //src/cats/dto/create-cat.dto.ts export class CreateIDDto{ name: string; id: number; } Request Payloads @Body() can be used for the POST route handler to accept client parameters 1 2 3 4 5 6 7 8 //src/cats/cats.controller.ts import { CreateCatDto } from \u0026#39;./dto/create-cat.dto\u0026#39;; @Post() create(@Body() createCatDto: CreateCatDto) { const {name, id} = createCatDto; return `This action adds a cat with name: ${name} and id: ${id}!` } This results in 1 2 curl -X POST http://localhost:3000/cats -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Kaeun\u0026#34;, \u0026#34;id\u0026#34;: 97}\u0026#39; # This action adds a cat with name: Kaeun and id: 97! DTO can also be used to retrieve information from a GET request Consider a case where we pass in GET http://localhost:3000/users?offset=0\u0026amp;limit=10 To use these input options in the GET request, we can do the following 1 2 3 4 5 // src/cats/dto/create-cat.dto.ts export class GetCatDto{ offset: number; limit: number; } 1 2 3 4 5 6 7 8 9 //src/cats/cats.controller.ts import {GetCatDto} from \u0026#39;./dto/create-cat.dto\u0026#39;; import { Query } from \u0026#39;@nestjs/common\u0026#39; @Get() getDto(@Query() info: GetCatDto){ const {offset, limit} = info; return `got offset: ${offset}, limit: ${limit}`; } This results in curl http://localhost:3000/cats?limit=10\u0026amp;offset=10, we get the following output 1 2 curl http://localhost:3000/cats?limit=10\u0026amp;offset=10 # got offset: 10, limit: 10 Controller and Module controllers always belong to a module controller must be included within the @Module() decorator for Nest to know that it exists (it will then create an instance of this controller class) 1 2 3 4 //src/app.module.ts @Module({ controllers: [CatIdController, AppController],//add controller here }) ","date":"2024-02-19T18:32:43+09:00","permalink":"https://k223kim.github.io/p/nestjs-controllers/","title":"Nestjs Controllers"},{"content":"Definition (By Kyle Simpson) Closure is when a function \u0026ldquo;remember\u0026rdquo; its lexical scope even when the function is executed outside that lexical scope Preserving access to a (private) variable It is not a snapshot of the variable This is an explanation of JavaScript Closure based on the document linked. 1 2 3 4 5 6 7 8 9 10 function makeFunc() { const name = \u0026#34;Mozilla\u0026#34;; function displayName() { console.log(name); } return displayName; } const myFunc = makeFunc();//Nothing myFunc();//\u0026#34;Mozilla\u0026#34; Above is the code example from the document. Couple things to notice:\nmakeFunc returns a reference to a function (it is not yet executed in makeFunc) const myFunc = makeFunc(); is used to invoke makeFunc. Therefore, myFunc reference to the instance of the function displayName This invoked makeFunc referenced my myFunc is invoked at the end (i.e. myFun()) Interestingly enough when displayName was invoked (in myFunc()), displayName maintains a reference to its lexical environment so it has access to name.\nPractical Usage Function factory \u0026hellip; Consequently, you can use a closure anywhere that you might normally use an object with only a single method.\nExample from MDN 1 2 3 4 5 6 7 8 9 10 11 function makeAdder(x) { return function add(y) { return x + y; }; } const add5 = makeAdder(5); const add10 = makeAdder(10); console.log(add5(2)); // 7 console.log(add10(2)); // 12 In the add5\u0026rsquo;s lexical scope, x = 5. In the add10\u0026rsquo;s lexical scope, x = 10. Notice how whenever we call add5, add has access to its\u0026rsquo; x which is 5 and the same thing applies for add10.\nClosure with Modules 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 const makeCounter = function () { let privateCounter = 0; function changeBy(val) { privateCounter += val; } return { increment() { changeBy(1); }, decrement() { changeBy(-1); }, value() { return privateCounter; }, }; }; This is equivalent to the following:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const makeCounter = function count() { let privateCounter = 0; function changeBy(val) { privateCounter += val; } return { increment : function increase(){ changeBy(1); }, decrement : function decrease(){ changeBy(-1); }, value : function val(){ return privateCounter; } }; }; makeCounter has three public functions: increment, decrement, and value.\n1 2 3 4 5 6 7 8 9 10 11 12 const counter1 = makeCounter(); const counter2 = makeCounter(); console.log(counter1.value()); // 0. counter1.increment(); counter1.increment(); console.log(counter1.value()); // 2. counter1.decrement(); console.log(counter1.value()); // 1. console.log(counter2.value()); // 0. Notice how counter1 does not have access to privateCounter nor changeBy but can access them by using the public functions. Those public functions have access to privateCounter and changeBy \u0008as they all form closures. (i.e. maintains a reference to its lexical environment)\nClosure scope chain 1 2 3 4 5 6 7 8 9 10 11 function outer() { let getY; { const y = 6; getY = () =\u0026gt; y; } console.log(typeof y); // undefined console.log(getY()); // 6 } outer(); Notice that there exists a inner scope that has the following:\n1 2 3 4 {//inner scope const y = 6; getY = () =\u0026gt; y; } Since const y has been declared from the inner scope, the outer scope does not have access to y. That is why console.log(typeof y); outputs undefined. However, as similar to above examples, we can access the private y by getY. Notice that although getY belongs to the outer scope, in the inner scope, getY is assigned to a reference to a function that returns y.\n1 2 3 4 5 6 {//inner scope const y = 6; getY = function returnY (){ return y; } } That being said, when outer is invoked, the outer scope can have access to y using getY. y can be considered \u0026lsquo;private\u0026rsquo; while getY is \u0026lsquo;public.\u0026rsquo;\nRead/Write private variables (proving that closure does not take \u0026lsquo;snapshots\u0026rsquo; of variables) 1 2 3 4 5 6 // myModule.js let x = 5; export const getX = () =\u0026gt; x; export const setX = (val) =\u0026gt; { x = val; }; 1 2 3 4 5 import { getX, setX } from \u0026#34;./myModule.js\u0026#34;; console.log(getX()); // 5 setX(6); //updates x to 6 console.log(getX()); // 6 Notice while x is only accessible at myModule.js, it can be written and read by using setX and getX. Interestingly enough, if we decide to export x, we can have a separate file that can access x.\n1 2 3 4 5 // myModule.js export let x = 1; export const setX = (val) =\u0026gt; { x = val; }; 1 2 3 4 // closureCreator.js import { x } from \u0026#34;./myModule.js\u0026#34;; export const getX = () =\u0026gt; x; // Close over an imported live binding This getX will have a scope chain as it returns x that is from a different scope.\n1 2 3 4 5 6 import { getX } from \u0026#34;./closureCreator.js\u0026#34;; import { setX } from \u0026#34;./myModule.js\u0026#34;; console.log(getX()); // 1 setX(2); console.log(getX()); // 2 Closure in loops Example 1 (from FrontEndMasters) 1 2 3 4 5 6 7 8 9 10 11 12 for (var i = 1; i \u0026lt;= 3; i++){ console.log(i); setTimeout(function(){ console.log(\u0026#39;i: ${i}\u0026#39;);//closing over i }, i*1000); } // 1 // 2 // 3 // i: 4 // i: 4 // i: 4 Couple things to note.\nCallback function Function passed into another function as an argument Types Synchronous Asynchronous 1 2 3 setTimeout(function(){ console.log(\u0026#39;i: ${i}\u0026#39;); }, i*1000); Above is an example of callback function. Specifically an asynchronous callback. To explain what happens, JavaScript Engine executes code in a stack. When it encounters an asynchronous callback, this is added to a callback queue (or a task queue). Then, whenever the stack is empty, any task in the queue is pulled out and is executed. Below example demonstrates how asynchronous callback work (see herefor details).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 function f1() { console.log(\u0026#39;f1\u0026#39;); } function f2() { console.log(\u0026#39;f2\u0026#39;); } function main() { console.log(\u0026#39;main\u0026#39;); setTimeout(f1, 0); f2(); } function next(){ console.log(\u0026#39;last\u0026#39;); } function next2(){ console.log(\u0026#39;last2\u0026#39;); } main(); next(); next2(); //main //f2 //last //last2 //f1 Notice how setTimeout is executed after all the synchronous parts are executed (i.e. after the stack is empty). That being said, considering our original for loop, we now know that setTimeout will be executed after the for loop. Also, notice how the for loop uses a var i. As per the document, var means the following:\nvar are not local to the loop, i.e. they are in the same scope the for loop is in.\n\u0008This means that var does not belong to the scope created by the for loop iteration. That is why when setTimeout is executed, it has access to the i in the outer scope that has a value of 4 (due to closure). To illustrate this behavior, it can be shown as the following\n1 2 3 4 5 6 7 8 9 10 11 var i = 4;//after the for loop setTimeout(function(){ console.log(\u0026#39;i: ${i}\u0026#39;);//closing over i }, i*1000); setTimeout(function(){ console.log(\u0026#39;i: ${i}\u0026#39;);//closing over i }, i*1000); setTimeout(function(){ console.log(\u0026#39;i: ${i}\u0026#39;);//closing over i }, i*1000); How can we resolve this? This can be resolved by making use of the scope.\nUsing let to create a new scope for each iteration. 1 2 3 4 5 6 7 8 9 10 for (var i = 1; i \u0026lt;= 3; i++){ let j = i; // new scope setTimeout(function(){ console.log(\u0026#39;j: ${j}\u0026#39;);//closing over j }, i*1000); } // j: 1 // j: 2 // j: 3 Notice how j belongs to the inner scope of the for loop. That being said, whenever setTimeout is called asynchronously, it has access to the local variable j that has been updated with i. Also note that this is equivalent to the following:\n1 2 3 4 5 6 7 8 9 for (let i = 1; i \u0026lt;= 3; i++){ setTimeout(function(){ console.log(\u0026#39;j: ${j}\u0026#39;);//closing over j }, i*1000); } // j: 1 // j: 2 // j: 3 Create another scope and pass in the variable (creating a local variable within that scope) 1 2 3 4 5 6 7 8 9 10 11 for (var k = 1; k \u0026lt;= 3; k++){ (function temp(j){ setTimeout(function(){ console.log(`j: ${j}`);//closing over j }, k*1000) })(k); } // j: 1 // j: 2 // j: 3 Notice that in the above code block, temp is executed synchronously with for. Also, temp has its\u0026rsquo; own scope for call in the for loop iteration. For the each scope, the k variable is passed in which will increment from 1 to 3. These k values will be assigned to j and print out accordingly.\n","date":"2024-02-07T13:10:36+09:00","permalink":"https://k223kim.github.io/p/javascript-closure/","title":"JavaScript Closure"},{"content":"Commit Convention Overview 1 2 3 4 5 \u0026lt;type\u0026gt;[optional scope]: \u0026lt;description\u0026gt; [blank] [optional body] [blank] [optional footer(s)] Type fix : bug fix feat : new feature etc build : changes that affect build system/external dependencies chore : updating grunt tasks (no production code change) ci : changes to CI configuration style : changes to the code style only (white-space, format, semic-colons, etc) refactor : not fix nor feat perf : improves performance test : adding/correcting tests docs : documentation change ! after type / scope draws attention (obviously) Footer BREAKING CHANGE breaking API change for any type/scope Signed-off-by Reviewed-by Helped-by Reference-to See-also Examples 1 fix: updated so that the API only takes valid uris 1 2 3 4 5 feat!: constantly checks for new ground truth dataset in the DB and trains the model BREAKING CHANGE: airflow DAG created to run this feature weekly Reviewed by: Kaeun Kim Branch Conventions Main Branches master : production-ready develop : latest development Supporting Branches feature branch off from develop when developing new features merge back to develop to add the new feature in the new release Naming convention: anything other than other branches convention release branch off from develop when develop (almost) reflects the desired state of the new release 1 git checkout -b release-1.1 develop merge back to \u0026hellip; master when it is ready to become a real release 1 2 3 git checkout master git merge --no-f release-1.1 git tag -a 1.1 develop for further development of the next release 1 2 git checkout develop git merge --no-f release-1.1 Naming convention: release-** hotfix branch off from master when it is necessary to act immediately upon an undesired state of a live production version 1 git checkout -b hotfix-1.0.1 master merge back to \u0026hellip; master when the bug fix is done 1 2 3 git checkout master git merge --no-ff hotfix-1.0.1 git tag -a 1.0.1 develop to safeguard the bug fix for the next release 1 2 git checkout develop git merge --no-f release-1.1 Naming convention: hotfix-** References https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#type https://www.conventionalcommits.org/en/v1.0.0/ https://nvie.com/posts/a-successful-git-branching-model/ ","date":"2023-12-04T00:08:07+09:00","permalink":"https://k223kim.github.io/p/git-conventions/","title":"Git Conventions"},{"content":"Stored Procedure Basics 1 2 3 4 CREATE PROCEDURE my_procedure() ([Parameter 1], [Parameter 2]) BEGIN SQL Queries END; Stored procedure is a collection of pre-compiled SQL statements wrapped within a CREATE PROCEDURE statement. Execution of a SQL query consists of the following steps (details): Compiling \u0026amp; Binding → Optimizing → Executing Compiling Parsing, syntax check, semantics check Convert to binary representation (execution plan) Optimizing Choose algorithms to use (optimize the execution plan) Executing Run query and fetch output As stored procedure is pre-compiled (already compiled on the server side(DB); first step of execution is done), it is faster than a MySQL function (this runs on the client; please see here for further details regarding the difference between a procedure and a function). Can be called as shown below: 1 call my_procedure() Stored Procedure Parameters Three modes for MySQL stored procedures: IN, OUT, and INOUT. IN: input parameters OUT: output parameters (returned parameters) INOUT: output parameter that is determined by the input parameter We must be also provide the datatype and its length. Below are some examples: IN parameter 1 2 3 4 CREATE PROCEDURE first_procedure(IN input_parameter varchar(50)) BEGIN ... END; 1 CALL first_procedure(\u0026#39;hello\u0026#39;) OUT parameter 1 2 3 4 CREATE PROCEDURE second_procedure(OUT returned_value int) BEGIN ... END; 1 2 CALL second_procedure(@val) SELECT @val as Output INOUT parameter 1 2 3 4 CREATE PROCEDURE third_procedure(INOUT returned_value int, IN input varchar(10)) BEGIN ... END; 1 2 CALL third_procedure(@out, \u0026#39;kaeun\u0026#39;); SELECT @out as Output; Viewing Stored Procedure 1 SHOW CREATE PROCEDURE my_procedure; Stored Procedure with JSON Let us consider the case where the input parameter is a JSON file. Consider the following json file.\n1 2 3 4 5 { \u0026#39;name\u0026#39;: \u0026#39;Kaeun Kim\u0026#39;, \u0026#39;age\u0026#39;: 27, \u0026#39;pets\u0026#39;: [\u0026#39;tico\u0026#39;, \u0026#39;hope\u0026#39;] } Also, consider a table info that has the following columns: name, age, pet. I want to create a stored procedure to filter out rows that has either the same pet as the input JSON, older than the input age.\n1 2 3 | name | age | pet | |------|-----|-----| | | | | This can be achieved by the following stored procedure my_procedure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 CREATE PROCEDURE my_procedure(json_info JSON) BEGIN SET @name = JSON_UNQUOTE(JSON_VALUE(json_info, \u0026#39;$.name\u0026#39;)) SET @age = JSON_VALUE(json_info, \u0026#39;$.age\u0026#39;) SET @pets = NULLIF(JSON_UNQUOTE(JSON_EXTRACT(json_info, \u0026#39;$.pets\u0026#39;)), \u0026#39;null\u0026#39;) SELECT DISTINCT info.name as name, info.age as age, info.pet as pet FROM info WHERE (@pets IS NULL OR images.pet MEMBER OF (@pets)) AND (@age IS NULL OR images.age \u0026gt; @age)\tEND; A possible output would be the following:\n1 2 3 4 5 | name | age | pet | |-------|-----|------| | John | 30 | None | | Peter | 28 | tico | | Tom | 29 | hope | Extracting Values from JSON Extract scalar value from JSON 1 JSON_VALUE(json_info, \u0026#39;$.name\u0026#39;) Extract any type of value from JSON 1 JSON_EXTRACT(json_info, \u0026#39;$.pets\u0026#39;) Variables (details) User-defined variables (i.e. session variable see here for details) Specific to the current client connection to the MySQL server. 1 SET @val = 10; Local Variables (Procedure variable) 1 2 3 4 5 6 7 8 9 10 11 DELIMITER // CREATE PROCEDURE my_procedure (input INT) BEGIN DECLARE val INT; SET val = 29; SELECT val; END; // DELIMITER ; Reinitialized to NULL each time the procedure is called References https://www.sqlshack.com/learn-mysql-the-basics-of-mysql-stored-procedures/ https://blog.duveen.me/12 ","date":"2023-11-30T10:12:24+09:00","permalink":"https://k223kim.github.io/p/stored-procedure/","title":"Stored Procedure"},{"content":"FCOS (Fully Convolutional One Stage Object Detection) The aim of this post is to fill the gap between the connectivity of the original paper and the code implementation as much as possible to fully understand the practical aspect of FCOS.\nThe key takeaways and strength of FCOS compared to other detector models are the following:\nIt is not a anchor based detector. It is a anchor-free/proposal free detector. There exists three branches; classification branch, regression branch, and center-ness branch. \u0008Because of that, its loss function is composed of the classification loss, regression loss, and a center-ness loss. FCOS Architecture FCOS Overview 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class GeneralizedRCNN(nn.Module): def forward(self, images, targets=None): images = to_image_list(images) features = self.backbone(images.tensors) proposals, proposal_losses = self.rpn(images, features, targets) if self.roi_heads: x, result, detector_losses = self.roi_heads(features, proposals, targets) else: # RPN-only models don\u0026#39;t have roi_heads x = features result = proposals detector_losses = {} if self.training: losses = {} losses.update(detector_losses) losses.update(proposal_losses) return losses return result FCOS architecture has three components:\nBackbone Input: images Output: features RPN Input : images, features, targets Output : proposals, proposal losses Usage : uses the image features to extract proposals Head Input: features, proposals, targets Output: (detection) result, detector losses Usage: uses the features from the backbone and the proposals from the RPN to get the final detection/segmentation output FCOS Module This is the main component of FCOS RPN that computes the proposals and proposal losses. Notice that to calculate the proposal losses, we need to compute the locations. This will be further discussed below when we talk about anchor-free detectors.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class FCOSModule(torch.nn.Module): \u0026#34;\u0026#34;\u0026#34; Module for FCOS computation. Takes feature maps from the backbone and FCOS outputs and losses. Only Test on FPN now. \u0026#34;\u0026#34;\u0026#34; def __init__(self, cfg, in_channels): super(FCOSModule, self).__init__() head = FCOSHead(cfg, in_channels) box_selector_test = make_fcos_postprocessor(cfg) loss_evaluator = make_fcos_loss_evaluator(cfg) self.head = head self.box_selector_test = box_selector_test self.loss_evaluator = loss_evaluator def forward(self, images, features, targets=None): box_cls, box_regression, centerness = self.head(features) locations = self.compute_locations(features) # computes the locations for each feature level if self.training: return self._forward_train( # calculates the training loss locations, box_cls, box_regression, centerness, targets ) else: return self._forward_test( # selects which box to use locations, box_cls, box_regression, centerness, images.image_sizes ) FCOS Head For clarity, please refer the following figure to understand each component of FCOS Head. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class FCOSHead(torch.nn.Module): def __init__(self, cfg, in_channels): super(FCOSHead, self).__init__() num_classes = cfg.MODEL.FCOS.NUM_CLASSES - 1 self.fpn_strides = cfg.MODEL.FCOS.FPN_STRIDES cls_tower = [] bbox_tower = [] \u0026#34;\u0026#34;\u0026#34; \u0008cls_tower = 4 conv layers bbox_tower = 4 conv layers \u0026#34;\u0026#34;\u0026#34; # initialize the bias for focal loss prior_prob = cfg.MODEL.FCOS.PRIOR_PROB bias_value = -math.log((1 - prior_prob) / prior_prob) torch.nn.init.constant_(self.cls_logits.bias, bias_value) self.scales = nn.ModuleList([Scale(init_value=1.0) for _ in range(5)]) # this refers to def forward(self, x): logits = [] bbox_reg = [] centerness = [] for l, feature in enumerate(x): cls_tower = self.cls_tower(feature) box_tower = self.bbox_tower(feature) logits.append(self.cls_logits(cls_tower)) if self.centerness_on_reg: centerness.append(self.centerness(box_tower)) else: centerness.append(self.centerness(cls_tower)) bbox_pred = self.scales[l](self.bbox_pred(box_tower)) if self.norm_reg_targets: bbox_pred = F.relu(bbox_pred) if self.training: bbox_reg.append(bbox_pred) else: bbox_reg.append(bbox_pred * self.fpn_strides[l]) else: bbox_reg.append(torch.exp(bbox_pred)) return logits, bbox_reg, centerness Notice that cls_tower and bbox_tower refers to the classification branch and regression branch from the original paper. Also, notice that the input x is a list of features on 5 different levels ($P_3$, $P_4$, $P_5$, $P_6$, $P_7$). This means that on each feature level, different bounding box regression predictions, center-ness, and logits are calculated. Note that the regression predictions on each feature level are literary in a feature-level. Additionally, the regression predictions are in the $[l, t, r, b]$ format in order to compute the center-ness later on.\n1 2 3 4 5 6 7 # FCOS/fcos_core/modeling/rpn/fcos/loss.py def compute_centerness_targets(self, reg_targets): left_right = reg_targets[:, [0, 2]] top_bottom = reg_targets[:, [1, 3]] centerness = (left_right.min(dim=-1)[0] / left_right.max(dim=-1)[0]) * \\ (top_bottom.min(dim=-1)[0] / top_bottom.max(dim=-1)[0]) return torch.sqrt(centerness) However, our target bounding boxes are in pixels (e.g. in a coco-format bounding box, it will be $[x, y, w, h]$). That being said, we have to convert the gt bounding box annotations (pixel level) to a feature-level bounding box annotations and convert the bbox annotation to a $[l,t,r,b]$ format.\nOne thing to note is how when we are performing inference of FCOS, we have to multiply the FPN strides to convert the feature-level regression output to a pixel level output. See the below code block to see how FCOSHead multiplies the FPN strides during inference:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def forward(self, x): logits = [] bbox_reg = [] centerness = [] for l, feature in enumerate(x): cls_tower = self.cls_tower(feature) box_tower = self.bbox_tower(feature) logits.append(self.cls_logits(cls_tower)) if self.centerness_on_reg: centerness.append(self.centerness(box_tower)) else: centerness.append(self.centerness(cls_tower)) bbox_pred = self.scales[l](self.bbox_pred(box_tower)) if self.norm_reg_targets: bbox_pred = F.relu(bbox_pred) if self.training: bbox_reg.append(bbox_pred) else: # during inferen bbox_reg.append(bbox_pred * self.fpn_strides[l]) else: bbox_reg.append(torch.exp(bbox_pred)) return logits, bbox_reg, centerness What does it mean to have a anchor-free detector? Anchor boxes can be viewed as pre-defined sliding windows or proposals, which are classified as positive or negative patches, with an extra offsets regression to refine the prediction of bounding box locations. \u0026hellip; (Anchor based detectors) often employ intersection over union (IOU) between anchor boxes and ground-truth boxes to determine the label of an anchor box.\nThe most common example of an anchor-based detector is Faster R-CNN. The following code block shows how Faster R-CNN uses anchors to calculate the (bounding box) regression loss. In order to calculate the regression loss, we have to figure out the regression target from the target bounding boxes and predefined anchors. See below how IOU (Intersection Over Union) is calculated for each target bounding box and anchor pair to get regression target along with their labels (whether it is an object or not/background or foreground).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # simplified code block from FCOS/fcos_core/modeling/rpn/loss.py def match_targets_to_anchors(self, anchor, target, copied_fields=[]): match_quality_matrix = boxlist_iou(target, anchor) matched_idxs = self.proposal_matcher(match_quality_matrix) # RPN doesn\u0026#39;t need any fields from target # for creating the labels, so clear them all target = target.copy_with_fields(copied_fields) # get the targets corresponding GT for each anchor # NB: need to clamp the indices because we can have a single # GT in the image, and matched_idxs can be -2, which goes # out of bounds matched_targets = target[matched_idxs.clamp(min=0)] matched_targets.add_field(\u0026#34;matched_idxs\u0026#34;, matched_idxs) return matched_targets def prepare_targets(self, anchors, targets): labels = [] regression_targets = [] for anchors_per_image, targets_per_image in zip(anchors, targets): # calculates iou between target bounding boxes and anchors # returns targets that matches the anchors matched_targets = self.match_targets_to_anchors( anchors_per_image, targets_per_image, self.copied_fields ) matched_idxs = matched_targets.get_field(\u0026#34;matched_idxs\u0026#34;) labels_per_image = self.generate_labels_func(matched_targets) labels_per_image = labels_per_image.to(dtype=torch.float32) # Background (negative examples) bg_indices = matched_idxs == Matcher.BELOW_LOW_THRESHOLD labels_per_image[bg_indices] = 0 # discard anchors that go out of the boundaries of the image if \u0026#34;not_visibility\u0026#34; in self.discard_cases: labels_per_image[~anchors_per_image.get_field(\u0026#34;visibility\u0026#34;)] = -1 # discard indices that are between thresholds if \u0026#34;between_thresholds\u0026#34; in self.discard_cases: inds_to_discard = matched_idxs == Matcher.BETWEEN_THRESHOLDS labels_per_image[inds_to_discard] = -1 # compute regression targets regression_targets_per_image = self.box_coder.encode( matched_targets.bbox, anchors_per_image.bbox ) labels.append(labels_per_image) regression_targets.append(regression_targets_per_image) return labels, regression_targets On the other hand, FCOS uses the following code block to convert the target bounding boxes to compute the regression target by calculating locations\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def prepare_targets(self, points, targets): object_sizes_of_interest = [ [-1, 64], [64, 128], [128, 256], [256, 512], [512, INF], ] expanded_object_sizes_of_interest = [] for l, points_per_level in enumerate(points): object_sizes_of_interest_per_level = \\ points_per_level.new_tensor(object_sizes_of_interest[l]) expanded_object_sizes_of_interest.append( object_sizes_of_interest_per_level[None].expand(len(points_per_level), -1) ) expanded_object_sizes_of_interest = torch.cat(expanded_object_sizes_of_interest, dim=0) num_points_per_level = [len(points_per_level) for points_per_level in points] self.num_points_per_level = num_points_per_level points_all_level = torch.cat(points, dim=0) labels, reg_targets = self.compute_targets_for_locations( points_all_level, targets, expanded_object_sizes_of_interest ) for i in range(len(labels)): labels[i] = torch.split(labels[i], num_points_per_level, dim=0) reg_targets[i] = torch.split(reg_targets[i], num_points_per_level, dim=0) labels_level_first = [] reg_targets_level_first = [] for level in range(len(points)): labels_level_first.append( torch.cat([labels_per_im[level] for labels_per_im in labels], dim=0) ) reg_targets_per_level = torch.cat([ reg_targets_per_im[level] for reg_targets_per_im in reg_targets ], dim=0) if self.norm_reg_targets: reg_targets_per_level = reg_targets_per_level / self.fpn_strides[level] reg_targets_level_first.append(reg_targets_per_level) return labels_level_first, reg_targets_level_first Personal Notes I got a chance to make use of the FCOS (specifically, CondInst and BoxInst). I\u0026rsquo;ve written what I wanted to note during different experiments and implementations down below.\nAdding new heads In order to use FCOS to calculate something else (other than detection or classification), using the bounding box features (or the classification feature, or maybe both), adding another head can be helpful. That means something like the following (+I realized how a \u0026lsquo;head\u0026rsquo; refers to a single convolutional layer.):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class FCOSHead(torch.nn.Module): def __init__(self, cfg, in_channels): super(FCOSHead, self).__init__() # original heads self.cls_logits = nn.Conv2d( in_channels, num_classes, kernel_size=3, stride=1, padding=1 ) self.bbox_pred = nn.Conv2d( in_channels, 4, kernel_size=3, stride=1, padding=1 ) self.centerness = nn.Conv2d( in_channels, 1, kernel_size=3, stride=1, padding=1 ) # adding another head self.volume_pred = nn.Conv2d(self.in_channels, 1, 3, padding=1) Feature map to pixel space (input image space) For each location $(x, y)$ on the feature map $F_i$ , we can map it back onto the input image as $(\\lfloor \\frac{s}{2}\\rfloor + xs, \\lfloor \\frac{s}{2} \\rfloor+ ys)$ which is near the center of the receptive field of the location $(x, y)$. ($s$ is the total stride until the layer)\nThis means that when the regression output is $[0.75, 0.6, 0.8, 0.8]$ at the feature level where the stride is 128, the actual predicted bounding box area is $(0.75 (left) + 0.8 (right))\\times (0.6(top) + 0.8 (bottom)) \\times 128^2 (stride)$.\nConcatenating features When concatenating input features, (here, I wanted to concatenate the classification features and bounding box regression features to make use of the class and the bounding box information all together) it can be done as the following\n1 2 3 4 5 6 7 8 ctrness_pred = self.ctrness(bbox_tower) reg_pred = self.bbox_pred(bbox_tower) logits_pred = self.cls_logits(cls_tower) reg_pred = F.relu(scale(reg_pred), inplace=True) #concatenate two features two_towers = torch.cat((bbox_tower, cls_tower), dim=1) reg_pred2 = self.another_head(two_towers) reg_pred2 = F.relu(reg_pred2, inplace=True) FCOS code structure breakdown I wanted to understand the original repository\u0026rsquo;s code structure (based on maskrcnn-benchmark\u0026rsquo;s structure). Some comments are added to the code structure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 . ├── configs # configs for each variation of model architecture ├── demo ├── docker ├── fcos │ ├── __init__.py │ ├── bin │ ├── configs -\u0026gt; ../configs/fcos │ └── fcos.py #main FCOS ├── fcos_core │ ├── README.md │ ├── __init__.py │ ├── config │ │ ├── __init__.py │ │ ├── defaults.py │ │ └── paths_catalog.py │ ├── csrc │ ├── data # handling dataset (e.g. dataset/loader, batch sampler, collate..) │ │ ├── __init__.py │ │ ├── build.py │ │ ├── collate_batch.py │ │ ├── datasets │ │ ├── samplers │ │ └── transforms │ ├── engine │ │ ├── __init__.py │ │ ├── bbox_aug.py │ │ ├── inference.py │ │ └── trainer.py │ ├── layers │ │ ├── __init__.py │ │ ├── _utils.py │ │ ├── batch_norm.py │ │ ├── dcn │ │ ├── iou_loss.py │ │ ├── misc.py │ │ ├── nms.py │ │ ├── roi_align.py │ │ ├── roi_pool.py │ │ ├── scale.py │ │ ├── sigmoid_focal_loss.py │ │ └── smooth_l1_loss.py │ ├── modeling # different components of the architecture │ │ ├── __init__.py │ │ ├── backbone # different backbones to extract features │ │ ├── detector │ │ │ ├── __init__.py │ │ │ ├── detectors.py │ │ │ └── generalized_rcnn.py │ │ ├── roi_heads # different heads │ │ │ ├── __init__.py │ │ │ ├── box_head │ │ │ ├── keypoint_head │ │ │ ├── mask_head │ │ │ └── roi_heads.py │ │ ├── rpn # different Region Proposal Networks │ │ │ ├── __init__.py │ │ │ ├── anchor_generator.py │ │ │ ├── fcos │ │ │ │ ├── __init__.py │ │ │ │ ├── fcos.py # has FCOS module and head │ │ │ │ ├── inference.py │ │ │ │ └── loss.py │ │ │ ├── inference.py │ │ │ ├── loss.py │ │ │ ├── retinanet │ │ │ │ ├── __init__.py │ │ │ │ ├── inference.py │ │ │ │ ├── loss.py │ │ │ │ └── retinanet.py │ │ │ ├── rpn.py # this has build_rpn() to call different rpns │ │ │ └── utils.py │ │ └── utils.py │ ├── solver │ ├── structures │ └── utils ├── onnx ├── requirements.txt ├── setup.py ├── tests └── tools ","date":"2023-11-17T14:31:50+09:00","permalink":"https://k223kim.github.io/p/fcos/","title":"FCOS"},{"content":" View process and GPU status 1 nvidia-smi Information of the process 1 ps -ef | grep ${PID number} ","date":"2023-10-25T23:42:52+09:00","permalink":"https://k223kim.github.io/p/linux-commands/","title":"Linux Commands"},{"content":"I often use coco format detection/segmentation dataset and want to note some useful commands. The library used for coco dataset is called pycocotools. Below are some common usage of pycocotools (for me at least).\n1 from pycocotools import coco Useage Loading coco dataset 1 2 coco_path = \u0026#39;/path/to/coco.json\u0026#39; coco_info = coco.COCO(coco_path) Loading images and appropriate annotations 1 2 3 imgs = coco_info.loadImgs(coco_info.getImgIds()) #all images in the dataset for img in imgs: anns = coco_info.loadAnns(coco_info.getAnnIds(imgIds=img[\u0026#39;id\u0026#39;])) Loading annotations based on categories 1 2 3 4 category_names = [\u0026#39;cls1\u0026#39;, \u0026#39;cls2\u0026#39;, \u0026#39;cls3\u0026#39;, \u0026#39;cls4\u0026#39;] thsc_ids = coco_info.getCatIds(catNms=category_names) ann_ids = coco_info.getAnnIds(catIds=thsc_ids) ann_info = coco_info.loadAnns(ann_ids) Overwriting the coco dataset and save to json 1 2 3 coco_info.dataset[\u0026#39;images\u0026#39;] = new_images # list of new images with open(\u0026#39;/path/to/new/coco.json\u0026#39;, \u0026#39;w+\u0026#39;) as f: json.dump(coco_info.dataset, f) ","date":"2023-10-25T21:57:42+09:00","permalink":"https://k223kim.github.io/p/coco-dataset-and-pycocotools/","title":"COCO dataset and pycocotools"},{"content":"Often times, you may have multiple github accounts in one Mac. Below are the steps to add ssh-key for multiple github accounts.\nGenerate SSH keys You must generate ssh keys for each github account. Make sure to have unique names for each key file. Notice that the email used for the ssh key generation is irrelevant to the github account. (In fact, as per this source, email is just a comment?)\n1 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; When prompted: Enter file in which to save the key, make sure to modify the name for each account (e.g. id_rsa_kaeun).\nAdd SSH key to Github Account Go to Settings/SSH and GPG Keys in your Github Account and add copy and paste the output of the following command.\n1 cat ~/.ssh/\u0026lt;ssh-key file name\u0026gt;.pub Modify ~/.ssh/config Add the following to your ~/.ssh/config file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 #user1 account Host github.com-user1 HostName github.com User git IdentityFile ~/.ssh/github-user1 IdentitiesOnly yes #user2 account Host github.com-user2 HostName github.com User git IdentityFile ~/.ssh/github-user2 IdentitiesOnly yes SSH agent 1 2 3 # ssh-add \u0026lt;IdentityFile\u0026gt; ssh-add **~/.ssh/${name of ssh key file}** # Use **eval \u0026#34;$(ssh-agent -s)\u0026#34;** if necessary Clone When cloning repositories run the following command.\n1 git clone git@${Host}:${user_name}/${your-repo-name}.git Delete recently pushed commit 1 2 git reset HEAD^ git push -f origin ${branch_name} References https://gist.github.com/Jonalogy/54091c98946cfe4f8cdab2bea79430f9 ","date":"2023-10-25T18:03:00+09:00","image":"https://k223kim.github.io/p/github-ssh-set-up/GitHub-Mark_hu9d76232819f01fb0167220a8ea045d21_7249_120x120_fill_box_smart1_3.png","permalink":"https://k223kim.github.io/p/github-ssh-set-up/","title":"Github Ssh Set Up"}]